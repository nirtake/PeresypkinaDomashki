### Задание 1 (5 баллов).

Ответьте на следующие вопросы (по возможности своими словами, а не копипастой):

1. Приведите классификацию формальных грамматик Хомского с примерами для категорий 2 и 3.
2. Что такое бейзлайн, пайплайн, SOTA? Приведите примеры. 
3. Какие элементы имплементации регулярного языка PCRE не являются собственно элементами грамматики регулярного языка по классификации Хомского?
4. Что такое языковая модель? Какие типы языковых моделей вы знаете?
5. Чем задача классификации отличается от задачи кластеризации?

1. Классификация Хомского:
0 - Неограниченные грамматики (нет ограничений на правила, по которым функционирует язык). Насколько я поняла, по таким грамматикам строятся естественные языки, а для создания формальных они не очень применяются, потому что слишком сложные.
1 - Контекстно-зависимые грамматики (применение правил грамматики ограничивается правым или левом контекстом цепочки, к которой они применяются).
2 - Контекстно-свободные грамматики. Контекстно-свободные языки описываются автоматами с магазинной памятью. К языкам с КС-грамматикой относятся все языки программирования.
Применение: синтаксические анализаторы структуры программ (напр. YACC), определение типа документов (markup languages, напр. HTML, XML), 
3 - Регулярные языки (самые простые грамматики, включены в класс КС-грамматик, как я поняла, все типы с 0 по 3 как бы включены друг в друга но на каждом уровне накладываются ограничения, но это не точно). Используются для конструирования простых элементов языка (констант, чисел, элементов словаря).
Применение: лексические анализаторы (Lex, Flex), команды поиска (регулярные выражения используются для описания шаблонов, которые ищутся в тексте).


2. Бейзлайн -- наиболее простое и очевидное решение для данной задачи. Сначала оно, а потом уже все остальные пытаются придумать что-то более сложное и эффективное. Если я правильно поняла, это одновременно и самый базовый подход к решению задачи (составление словарей позитовно и негативно окрашенных слов для сентимент-анализа и их поиск в тексте) и базовые модели/системы, с результатами работы которых сравнивают новые (и если результаты хуже, то совсем плохо).

Пайплайн -- последовательность процессов (шагов), которая должна быть выполнена для решения задачи.
Пример: Пайплайн SpaCy для обработки текста: Tokenizer - Tagger - Parser (dependency parser) - Ner (named entity recognition) - Lemmatizer - Textcat (text category assigning) - Custom (custom attributes assigning)

SOTA = State-of-the-Art -- решение задачи (модель), которая показывает в настоящий момент времени наиболее высокие результаты (измеряемые установленными в рамках данной задачи метриками).
Примеры (я надеюсь, что они, все еще актуальны):
Bidirectional Encoder Representations from Transformers (BERT) -- используется в NLU, возможно, уже не SOTA
Модель FRED-5
Для русского языка -- HUMAN BENCHMARK (по версии russian superglue)

3. 

4. Языковая модель -- алгоритм, вычисляющий вероятностное распределение слов в тексте и вероятность появления слова в предложении на основе этого распределения.
Типы языковых моделей:
n-грамные модели (для вычисления вероятности появления слова смотрим на n предыдущих слов и вероятность их встречаемости вместе)
модели, использующие векторы (эмбеддинги) для представления слов ( на их основе собирается информация о семантике слова)
модели, использующие эмбеддинги, зависящие от контекста
модели, восстанавливающие слова (эмбеддинги) по контексту (Masked Language Modelling)


5. При классификация есть заранее определенные классы, по которым распределяются объекты (тексты), а при кластеризации заранее неизвстно, на какие категории нужно распределить объекты и они объединяются в группы на основе схожести.


### Задание 2 (10 баллов). 

Попробуйте самостоятельно разработать метрики для оценки качества автоматического морфологического анализа: как бы вы оценивали качество лемматизации, приписывания частей речи и морфологических характеристик? Подумайте, какие вещи необходимо учесть. В результате у вас должны получиться три формулы, в которых будут фигурировать y_true (правильные ответы) и y_pred (предсказанные парсером ответы). Для морфологических признаков ответ явно будет складываться из нескольких категорий, например, род, число и падеж, нужно это учесть. Опишите словами ход своих рассуждений, приведите аргументы. Можно отталкиваться от уже существующих метрик, но если берете готовые, нужно их проанализировать.

### Задание 3 (10 баллов). 

Выберите любую понравившуюся вам задачу NLP и исследуйте литературу по этой задаче. Какой у нее бейзлайн? Какая SOTA? В каком направлении ведутся современные исследования, связанные с этой задачей? Какие практические применения? Напишите коротенький конспект. 

Рекомендация: попробуйте искать survey - статьи на scholar.google.com.

Диалоговые системы
Ранние подходы (обзор 1997 г.):
Диалоговый менеджер состоял из нескольких блоков (модулей): блок распознавания речи (на вход подавался текст/записанная речь, блок извлечения значений, блоки координировались между собой для разрешения неоднозначности в тексте, затем информация передавалась в блок генерации ответа, из текстового ответа на выходе могла генерироваться звучащая речь или изображение. Текст, получаемый на вход, преобразовывался в языковую модель, в блок распознавания речи входил парсер, также отдельными модулями могли решаться проблемы распознавания анафор и эллипсиса, толкования прагматики текста. В блок, извлекающий значения, входили: модели речевых актов, базовые данные о предмете диалога. Для построения модели диалога в отдельный блок включались модули отвечающие за стратегию взаимодействия, исправление ошибок, допущенных в ходе диалога.
Насколько я поняла, сначала модули работали последовательно, а затем начали развиваться системы, в которых они (все или некоторые) работали одновременно.
Основные подходы к моделированию диалога:
-семантический 
-диалоговые грамматики: правила построения цепочек (предложений) в диалог описывались в форме графов, конечных автоматов или просто наборов правил. Проблема: конечный автомат учитывал только последний контекст (последнюю часть предложения) при генерации ответа, а в человеческой речи запрос на ответ не всегда содержится в конце реплики и не всегда один.
-подход, основанный на распознавании цели говорящего (plan-based): основывался на том, что участники диалога, вступая в коммуникацию, преследуют определенную цель, и для генерации ответа эту цель необходимо понять. В ходе диалога из общих целей извлекались более мелкие составляющие, для установления которых использовался корпус диалогов. Подразумевалось, что главной целью диалога было удовлетворение запроса человека, в нем участвовавшего, поэтому ответы на вопросы могли быть не совсем нормальными для живой речи (напр. на вопрос “Где мне найти x?” можно было получить ответ “Сколько x вам нужно?”)
-теория речевых игр (Conversational Game Theory): подходит для диалоговых систем, ориентированных на решение конкретных задач (task-oriented), содержит уровень с целью диалога, “игрой” в ходе диалога считается цикл вопрос-ответ, в ходе которого решается какая-то подзадача, что в итоге приводит к решению главной задачи диалога (в целом, подвид предыдущего пункта). Изначально теория была использована как схема кодирования для исследования интонационных контуров в корпусе  HCRC Map Task Corpus.
-коллаборативные подходы: рассматривают диалог не только как средство решения конкретной задачи пользователя, но и как процесс коммуникации. Система моделирует позиции сторон, вступающих в диалог, базово считается, что одна сторона делает предложение, а вторая либо принимает его, либо нет. Оба участника диалога взаимодействуют для достижения предложенной цели.
Сложности, с которыми боролись:
-распознавание анафор
-распознавание эллипсиса
-распознавание слов, заполняющих паузы в речи (conversational fillers)
-непрямое выражение значения в речи (выражение намерения фразой, непосредственно из структуры которой это намерение извлечь нельзя)
-сопоставление вопроса и ответа, если ответ не следует непосредственно после вопроса (напр. в случае ответа вопросом на вопрос)
Ранние диалоговые системы:
SHRDLU system at MIT (очень узкая область задач)
HAM-RPM, TEAM (менее ограниченная область задач)
С развитием статистических методов и нейронных сетей появились не только письменные, но и разговорные (устные?) диалоговые системы.

Сейчас:
Переход от диалоговых систем, рассчитанных на решение узкого круга задач, к диалоговым системам, круг задач для которых не ограничен (closed-domain – open domain), появление мультимодальных (в том числе распознающих выражение лица, жестов и т.д.), многоязычных и систем, с количеством участников диалога большим, чем 2.
Использование больших языковых моделей, машинного обучения, нейронных сетей.
Первые (или одни из первых) мультимодальные системы:
ALFRESCO 
XTRA
С развитием систем извлечения информации, появились открытые (open-domain) диалоговые системы, которые для ответов на вопросы пользователей извлекали информацию из открытых данных Интернета.
Система SMARTWEB: объединяла знания определенной области, представленные в виде графов и команды для поисковых запросов, а также использовала статистические методы для извлечения нужной информации из найденных документов.
Большие языковые модели (LLM-powered language generators) на данный момент позволяют генерировать тексты, которые сложно отличить от написанных человеком. 
Задачи:
-поддержание живого человеческого диалога (инициатива в диалоге  исходит не только от человека, но и от самой системы, добавление эмоциональной окраски речи)
-проверка работы систем на максимах Грайса
-объединение символического (символьного?) и нейронных подходов (neuro-symbolic methods)
Как я поняла, SOTA – это что-то из трансформеров (какие конкретно – не поняла).




### Задание 4 (15 баллов). 

Возьмите любой достаточно большой conll-файл и проведите мини-исследование, связанное с дативно-предикативными конструкциями (такими, как "мне холодно" и "сегодня холодно": предикативы такого рода могут присоединять дополнение в дат.п., а могут не присоединять), по [статье](https://www.dialog-21.ru/media/5937/zimmerlingav120.pdf) А.В. Циммерлинга. Вам понадобится написать скрипт, в котором будут автоматически рассчитываться метрики, приведенные Циммерлингом в своей статье. Придется учесть, что в формате UD нет части речи "предикатив" (можно посчитать метрики только для n верхних предикативов в его таблице - это будут конкретные слова), и подумать о том, как собирать все зависимые для текущего проверяемого токена. Советую взять Синтагрус (либо можно разобрать свои собственные тексты, но если будет их слишком мало, у вас метрики будут близки к нулю или просто нули). Для части группы, которая умеет писать код в классах, настойчиво советую оформить это в класс. 
